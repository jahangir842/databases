# **Scenario-Based MongoDB Interview Questions (with Answers)**

### *(Highly practical ‚Äî the type asked in real DevOps/Cloud interviews)*

---

# **1Ô∏è‚É£ Scenario: MongoDB Primary Went Down During Peak Traffic**

**Question:**
Your MongoDB primary node has crashed during peak traffic. Reads are working from secondaries, but writes are failing. What steps do you take?

**Answer Approach:**

1. **Check replica set status**

   ```javascript
   rs.status()
   ```
2. See if an election happened.
3. If no election ‚Üí check:

   * network partition
   * heartbeat failure
   * replication lag
4. If nodes are available but no election occurs ‚Üí ensure:

   * majority of nodes are online
   * priority is set correctly
5. If necessary ‚Üí force reconfigure to elect a new primary.

**Commands**

```javascript
rs.stepDown()
rs.reconfig(config)
```

**Memorization Trick:**
**When primary dies ‚Üí L.E.A.D**

* **L**ag?
* **E**lection?
* **A**vailability?
* **D**rivers failing over?

---

# **2Ô∏è‚É£ Scenario: Your MongoDB Instance is Becoming Very Slow**

**Question:**
Users complain queries are too slow. CPU is high. What do you check first?

**Expected Answer:**

1. **Check slow query logs**

   ```javascript
   db.system.profile.find().sort({millis: -1}).limit(5)
   ```
2. **Check indexes**

   * Missing index?
   * Inefficient queries?
3. **Check replication lag**
4. **Check WiredTiger cache usage**

   ```javascript
   db.serverStatus().wiredTiger.cache
   ```
5. **Check working set size > RAM**
6. **Shard the collection if extremely large**

**Example:**
Query uses regex ‚Üí full collection scan ‚Üí add index.

---

# **3Ô∏è‚É£ Scenario: Your MongoDB Disk Is Full**

**Question:**
MongoDB is down because the disk is 100% full. How do you fix it without data loss?

**Steps:**

1. Stop writes (maintenance mode).
2. Compress old logs / move logs to another disk.
3. Verify WiredTiger journal files.
4. Extend disk using cloud provider:

   * AWS: expand EBS
   * Azure: expand managed disk
5. Start MongoDB.

**Command**

```bash
sudo systemctl restart mongod
```

**Extra:** Ensure log rotation is configured.

---

# **4Ô∏è‚É£ Scenario: A Sharded MongoDB Cluster Has a Hot Shard**

**Question:**
One shard has too much data. Others are almost empty. Why and how to fix?

**Reason:**
Bad shard key ‚Üí uneven distribution.

**Fix:**

1. Choose a **better shard key** (e.g., hashed).
2. Enable sharding with new key (requires collection recreation).
3. Migrate data:

```javascript
sh.enableSharding("ecom")
sh.shardCollection("ecom.orders", { userId: "hashed" })
```

**Why hashed?**
Even distribution, no hotspot.

---

# **5Ô∏è‚É£ Scenario: You Must Take Backup of a 1TB MongoDB**

**Question:**
What backup strategy do you use for a huge production database?

**Answer:**

* **Logical backup (mongodump)** ‚Üí too slow for 1TB
* **Use filesystem-level snapshots**

  * AWS EBS snapshot
  * Azure VM snapshot
  * LVM snapshot
* **Take backup from secondary** to avoid load on primary
* **If on Atlas ‚Üí use continuous backup**

**Example:**

```bash
sudo lvcreate -L 10G -s -n mongo_snap /dev/vg0/mongodata
```

---

# **6Ô∏è‚É£ Scenario: A Query Is Not Using Indexes**

**Question:**
A collection has an index but queries are still slow. Why?

**Possible Reasons:**

* Query fields order not matching compound index
* Using `$regex` beginning with wildcard
* Missing index on nested field
* Low cardinality field
* Wrong data types (string vs int)
* Mongo chooses wrong index ‚Üí use **hint()**

**Example**

```javascript
db.users.find({age: 25}).hint({age: 1})
```

---

# **7Ô∏è‚É£ Scenario: Write Concern Slowing Down Your App**

**Question:**
You used write concern:

```json
{ w: "majority", j: true }
```

Now latency is high. What do you do?

**Possible Solutions:**

* Lower write concern to `w:1` for non-critical writes
* Remove journaling for logs / analytics
* Send heavy writes to a separate collection
* Use **bulk writes** to reduce overhead

**Example**

```javascript
db.logs.insertMany(docs, { ordered: false })
```

---

# **8Ô∏è‚É£ Scenario: Your Data Exceeds a Single Node‚Äôs Storage**

**Question:**
You have a replica set but data is now larger than 1 node‚Äôs disk. What should you do?

**Answer:**

* Replication **does not distribute** data
* Only sharding can distribute storage
* Create a sharded cluster

**Steps:**

1. Deploy Config servers
2. Deploy mongos router
3. Add shards
4. Shard collections

**Memorization Trick:**
**Replica = copies, Shard = split**.

---

# **9Ô∏è‚É£ Scenario: MongoDB Connection Pool Exhausted**

**Question:**
Your API logs show:
`MongoTimeoutError: connection pool exhausted`

**Fix:**

* Increase connection pool size
* Ensure app closes unused connections
* Add more application instances
* Add more mongod/mongos to balance load

**Example for Node.js**

```javascript
maxPoolSize: 200
```

---

# **üîü Scenario: MongoDB Change Streams Not Working**

**Question:**
You enabled Change Streams, but no events are received.

**Possible Causes:**

* You are not connected to a **replica set**
* Feature requires **replica set or sharded cluster**
* Wrong read concern (must be majority)
* No oplog available

**Fix Example**

```yaml
replication:
  replSetName: "rs0"
```

---

# **1Ô∏è‚É£1Ô∏è‚É£ Scenario: You Need to Enforce Unique Field Across Many Documents**

**Question:**
How do you ensure no two users can register with the same email?

**Answer:**
Use a **unique index**.

```javascript
db.users.createIndex({ email: 1 }, { unique: true })
```

If duplicates already exist ‚Üí remove them first.

---

# **1Ô∏è‚É£2Ô∏è‚É£ Scenario: You Need Geo-Location Search**

**Example Use:** Find all drivers within 5 km.

**Solution:**
Use 2dSphere index.

```javascript
db.drivers.createIndex({ location: "2dsphere" })
```

Query:

```javascript
db.drivers.find({
  location: {
    $near: {
      $geometry: { type: "Point", coordinates: [74.352, 31.520] },
      $maxDistance: 5000
    }
  }
})
```

---

# **1Ô∏è‚É£3Ô∏è‚É£ Scenario: Replica Lag Increasing**

**Possible Reasons:**

* Slow disk I/O
* Secondary overloaded
* Large write bursts
* Network latency
* Oplog too small

**Fix:**

* Increase oplog size

```javascript
rs.printReplicationInfo()
```

* Move hidden secondaries to powerful servers
* Reduce write traffic or batch writes

---

# **1Ô∏è‚É£4Ô∏è‚É£ Scenario: MongoDB Memory Usage is Very High**

**Reason:**
WiredTiger uses RAM aggressively for cache.

**Fix:**

* Tune WiredTiger cache size
* Check working set size
* Add more RAM
* Move large collections to sharding

---

# **1Ô∏è‚É£5Ô∏è‚É£ Scenario: Need to Migrate SQL ‚Üí MongoDB**

**Approach:**

1. Identify entities ‚Üí collections
2. Convert tables ‚Üí documents
3. Replace joins ‚Üí embedded docs or references
4. Use indexes for speed

**Example Migration**
SQL:

```
users
orders
```

Mongo:

```json
{
  "name": "Ali",
  "orders": [
    { "id": 1, "item": "Laptop" }
  ]
}
```

---
